# ğŸ§  Stock Alert Dashboard â€” Detailed Team README

**Team:**

* **Aseem** â†’ Frontend (React Dashboard)
* **Atulya** â†’ Backend (FastAPI + PostgreSQL)
* **Zaid** â†’ Scraper (Data from Blinkit, Zepto, etc.)
* **Manoj** â†’ Alerts & Deployment (Twilio + Hosting)

---

## ğŸŒ 1. FRONTEND (Aseem) â€” React Dashboard

### ğŸ¯ Objective

Create an intuitive **dashboard interface** for D2C brands to monitor stock status across dark stores, pincodes, and SKUs in real-time.

### âš™ï¸ Tech Stack

* **React.js (Vite or CRA)**
* **Axios / Fetch API** for backend calls
* **Chart.js / Recharts** for visualizations
* **TailwindCSS / Material UI** for styling
* **React Router** for navigation

### ğŸ§© Folder Structure

```
frontend/
â”œâ”€â”€ public/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/        # Reusable UI components (Cards, Charts)
â”‚   â”œâ”€â”€ pages/             # Pages like Dashboard, AlertsHistory, Login
â”‚   â”œâ”€â”€ services/          # API call helpers
â”‚   â”œâ”€â”€ App.js
â”‚   â””â”€â”€ main.jsx
â””â”€â”€ package.json
```

### ğŸš€ Setup Steps

1. **Navigate to folder:**

   ```bash
   cd frontend
   ```
2. **Install dependencies:**

   ```bash
   npm install
   ```
3. **Run app locally:**

   ```bash
   npm run dev
   ```
4. **Environment variables:**
   Create `.env` file:

   ```
   REACT_APP_API_BASE=http://localhost:8000
   ```
5. **API Connections:**

   * `/pincodes` â†’ List of monitored pincodes
   * `/darkstores/{pin}` â†’ Get all dark stores for a pin
   * `/skus/{store_id}` â†’ Get SKU details
   * `/alerts` â†’ Get alert history

### ğŸ§  Key Responsibilities

* Create dashboard layout with **Sidebar (Pincode list)** and **Main Panel (Dark store cards)**
* Integrate backend API
* Use charts to show stock % (donut/pie)
* Ensure **mobile responsiveness**

---

## âš™ï¸ 2. BACKEND (Atulya) â€” FastAPI + PostgreSQL

### ğŸ¯ Objective

Provide REST APIs that serve the latest stock data, alert history, and analytics to the frontend.

### ğŸ§° Tech Stack

* **FastAPI (Python)**
* **PostgreSQL** (or SQLite for testing)
* **SQLAlchemy** ORM
* **Pydantic** for request/response models
* **Uvicorn** for local server

### ğŸ§© Folder Structure

```
backend/
â”œâ”€â”€ main.py                  # Entry point
â”œâ”€â”€ models/                  # SQLAlchemy models
â”œâ”€â”€ routes/                  # API endpoints
â”œâ”€â”€ schemas/                 # Pydantic models
â”œâ”€â”€ database.py              # DB connection logic
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env.example
```

### ğŸš€ Setup Steps

1. **Navigate to backend:**

   ```bash
   cd backend
   ```
2. **Create and activate virtual environment:**

   ```bash
   python -m venv venv
   source venv/bin/activate  # macOS/Linux
   venv\\Scripts\\activate   # Windows
   ```
3. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
   ```
4. **Run FastAPI server:**

   ```bash
   uvicorn main:app --reload
   ```
5. **Example `.env.example`:**

   ```
   DATABASE_URL=postgresql://user:password@localhost:5432/stockdb
   TWILIO_ACCOUNT_SID=xxxxx
   TWILIO_AUTH_TOKEN=xxxxx
   TWILIO_PHONE_NUMBER=xxxxx
   ```

### ğŸ§  Endpoints (to be implemented)

| Endpoint            | Method | Description                           |
| ------------------- | ------ | ------------------------------------- |
| `/pincodes`         | GET    | Get list of monitored pincodes        |
| `/darkstores/{pin}` | GET    | Get dark stores under that pincode    |
| `/skus/{store_id}`  | GET    | Get SKU availability for a dark store |
| `/alerts`           | GET    | Fetch alert history                   |
| `/alerts`           | POST   | Add a new alert triggered by scraper  |

---

## ğŸ¤– 3. SCRAPER (Zaid) â€” Data Collection Layer

### ğŸ¯ Objective

Collect stock availability data from **Blinkit**, **Zepto**, and **Swiggy Instamart**, simulate hyperlocal data per pincode, and output in a **standardized JSON** used by the backend.

### âš™ï¸ Tech Stack

* **Python + Selenium / Playwright**
* **BeautifulSoup4** for parsing HTML
* **JSON / CSV** for output
* Optional: **Proxy rotation** for safe scraping

### ğŸ§© Folder Structure

```
scraper/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ blinkit_scraper.py
â”‚   â”œâ”€â”€ zepto_scraper.py
â”‚   â””â”€â”€ instamart_scraper.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_output.json
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### ğŸš€ Setup Steps

1. **Navigate:**

   ```bash
   cd scraper
   ```
2. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
   ```
3. **Run scraper:**

   ```bash
   python scripts/blinkit_scraper.py
   ```
4. **Output Format (`sample_output.json`):**

   ```json
   {
     "pincode": "400001",
     "dark_stores": [
       {
         "store_id": "BL123",
         "platform": "Blinkit",
         "skus": [
           { "name": "Mango Oatmeal", "price": 120, "stock": 0, "competitor_stock": "Full" }
         ]
       }
     ]
   }
   ```

### ğŸ§  Responsibilities

* Maintain data accuracy (95% target).
* Avoid overloading platforms â€” add delay/random sleep.
* Push JSON to backend API every 10 mins via cron/scheduler.

---

## ğŸ’¬ 4. ALERTS & DEPLOYMENT (Manoj)

### ğŸ¯ Objective

Send **WhatsApp alerts** when SKUs go out of stock and handle deployment of backend + frontend.

### âš™ï¸ Tech Stack

* **Twilio API** (WhatsApp messaging)
* **Python (requests)** for sending alerts
* **Render / AWS / Railway** for backend deployment
* **Vercel / Netlify** for frontend deployment

### ğŸ§© Folder Structure

```
alerts/
â”œâ”€â”€ whatsapp_alerts.py
â”œâ”€â”€ deploy_notes.md
â””â”€â”€ .env.example
```

### ğŸš€ Setup Steps

1. **Create `.env` file:**

   ```
   TWILIO_ACCOUNT_SID=xxxx
   TWILIO_AUTH_TOKEN=xxxx
   TWILIO_PHONE_NUMBER=whatsapp:+14155238886
   BRAND_PHONE_NUMBER=whatsapp:+91XXXXXXXXXX
   ```

2. **Run test alert:**

   ```bash
   python whatsapp_alerts.py
   ```

3. **Sample Alert Message:**

   ```
   ğŸš¨ Stock Alert ğŸš¨
   You're OOS in Blinkit Store #123 (Pin 400001)
   Last week demand: 50 units
   Rivals fully stocked â€” restock ASAP!
   ```

4. **Deployment Notes:**

   * **Backend:** Use Render â†’ Connect GitHub repo â†’ Auto deploy on push
   * **Frontend:** Deploy to Vercel â†’ Connect to same repo
   * **Scraper:** Set up cron job on Railway or Replit for auto-run every 10 mins
   * Ensure `.env` variables are added to hosting environments

---

## ğŸ—“ï¸ Suggested 4-Week Plan

| Week | Focus                                             | Owner(s)     |
| ---- | ------------------------------------------------- | ------------ |
| 1    | Set up project structure + dummy APIs + sample UI | All          |
| 2    | Backend endpoints + scraper JSON format finalized | Atulya, Zaid |
| 3    | Alerts integration + UI linking with backend      | Aseem, Manoj |
| 4    | Testing + deploy + pilot demo with 2â€“3 brands     | All          |

---

## ğŸ§­ Summary

| Module       | Owner  | Deliverable                  |
| ------------ | ------ | ---------------------------- |
| **Frontend** | Aseem  | React Dashboard (3â€“4 pages)  |
| **Backend**  | Atulya | FastAPI APIs + Database      |
| **Scraper**  | Zaid   | JSON feed every 10 mins      |
| **Alerts**   | Manoj  | WhatsApp alerts + Deployment |


